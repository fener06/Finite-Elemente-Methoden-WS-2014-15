\section{Finite Differenzen}


\begin{Definition}
    \label{def:2.1}
    Sei $u\in C(\Omega)$, $x\in \Omega\subset \R^d$ offen und $h > 0$
    hinreichend klein. Dann definiere
    \begin{enumerate}[a)]
	\item
	    den einseitigen und zentralen Differenzenquotienten durch
	    \begin{eqnarray*}
                \partial_i^+ u(x)
            &=& \frac{1}{h} \left(u\left(x + h e^i\right) - u(x)\right), \\
                \partial_i^- u(x)
            &=& \frac{1}{h} \left(u(x) - u\left(x - h e^i\right)\right), \\
                \partial_i^0 u(x)
            &=& \frac{1}{2h} \left(u\left(x + h e^i\right)
                - u\left(x - h e^i\right)\right).
	    \end{eqnarray*}
	\item
	    den Differnzenquotienten 2. Ordnung durch
	    \begin{eqnarray*}
                \partial_i^+ \partial_i^- u(x)
            &=& \frac{1}{h^2} \left(u\left(x + h e^i\right) - 2u(x)
                + u\left(x - h e^i\right)\right).
	    \end{eqnarray*}
	\item
	    den diskreten Laplace-Operator durch
	    \begin{eqnarray*}
                \Delta_h u(x)
            &=& \sum_{i=1}^d \partial_i^+ \partial_i^- u(x).
	    \end{eqnarray*}
    \end{enumerate}
\end{Definition}


\begin{Beispiel}
    Für $u\in C(\Omega)$ und den diskreten Laplace-Operator gilt dann
    \begin{eqnarray*}
            \Delta_h u(x_1, x_2)
        &=& \frac{1}{h^2} (u(x_1 + h, x_2) + u(x_1 - h, x_2) - 4u(x) \\
            && + u(x_1, x_2 + h) + u(x_1, x_2 - h)).
    \end{eqnarray*}
\end{Beispiel}


\begin{Bemerkung}
    Wenn $u$ hinreichend glatt ist, gilt
    \begin{enumerate}[a)]
	\item
	    für den einseitigen und zentralen Differenzenquotienten
	    \begin{eqnarray*}
                |\partial_i^+ u(x) - \partial_i u(x)|
            &\le& Ch \|\partial_{h, i}^2 u\|_\infty, \\
                |\partial_i^- u(x) - \partial_i u(x)|
            &\le& Ch \|\partial_i^2 u\|_\infty, \\
                |\partial_i^0 u(x) - \partial_i u(x)|
            &\le& Ch^2 \|\partial_i^3 u\|_\infty. \\
	    \end{eqnarray*}
	\item
	    für den Differenzenquotienten 2. Ordnung
	    \begin{eqnarray*}
                |\partial_i^+\partial_i^- u(x) -
                \partial_i^2 u(x)|
            &\le& Ch^2 \|\partial_i^4 u\|_\infty.
	    \end{eqnarray*}
	\item
	    für den diskreten Laplace-Operator
	    \begin{eqnarray*}
                |\Delta_h u(x) - \Delta u(x)|
            &\le& Ch^2 \sum_{i=1}^d \|\partial_i^4 u\|_\infty.
	    \end{eqnarray*}
    \end{enumerate}
\end{Bemerkung}


\begin{Kartesische Gitter in 2-d}
    Sei $\Omega = [a_1, b_1] \times [a_2, b_2]$ und $\ N_1, \ N_2\in \N$. \\
    Wir definieren dann die Schrittweiten und Gitterpunkte durch
    \begin{eqnarray*}
        h_k = \frac{b_k - a_k}{N_k + 1}, \quad
        x_{n j} =	\begin{pmatrix}
                        a_1 + n h_1 \\
                        a_2 + j h_2
                    \end{pmatrix}.
    \end{eqnarray*}
    Der Raum der inneren Gitterpunkte und der Randpunkte ist definiert
    durch
    \begin{eqnarray*}
            \Omega_h
        &=& \{x_{n, j} \colon 1 \le n \le N_1, \ 1 \le j \le N_2\}, \\
            \partial\Omega_h
        &=& \{x_{n, j} \colon 0 \le n \le N_1 + 1 \text{ und } j = 0
            \text{ oder } j = N_2 + 1, \\
            && 0 \le j \le N_2 + 1 \text{ und } n = 0 \text{ oder }
            n = N_1 + 1\}.
    \end{eqnarray*}
    Die Gesamtheit aller Gitterpunkte ist dann
    $\overline\Omega_h = \Omega_h \cup \partial\Omega_h$.
\end{Kartesische Gitter in 2-d}

Desweiteren sei $V_h = \{u_h \colon \overline\Omega_h \rightarrow \R\}$ der
Raum der Gitterfunktionen, und
\begin{eqnarray*}
    I_h \colon C(\overline\Omega) &\rightarrow& V_h, \\
    u &\mapsto& (I_h u)(x) = u(x) \quad \text{für alle } x\in
    \overline\Omega_h
\end{eqnarray*}
die Gitterinterpolation. Dann setzen wir
\begin{eqnarray*}
      \|u_h\|_{\infty, \overline\Omega_h}
    = \|u_h\|_\infty
    = \max_{x\in \overline\Omega_h} |u_h(x)|.
\end{eqnarray*}


\subsection{Finite-Differenzen-Diskretisierung (FD)}


\begin{enumerate}[A)]
    \item 	
	Poisson-Problem (mit Dirichlet-Ranbedingungen) und $u\in
	C^2(\Omega) \cap C(\overline\Omega)$. Die PDE ist
	\begin{eqnarray*}
            -\Delta u(x)
	    &=& f(x) \qquad x\in \Omega \\
            u(x)
	    &=& g(x) \qquad x\in \partial\Omega.
	\end{eqnarray*}
	Die FD-Diskretisierung mit $u_h\in V_h$ ist dann gegeben durch
	\begin{eqnarray*}
            -\Delta_h u_h(x)
	    &=& f(x) \qquad x\in \Omega_h \\
            u_h(x)
	    &=& g(x) \qquad x\in \partial\Omega_h.
	\end{eqnarray*}
     \item
	Konvektions-Diffusions-Problem mit $u\in C^2(\Omega) \cap
    C(\overline\Omega)$.
	Für die PDE gilt
	\begin{eqnarray*}
            L u(x)
	    &=& f(x) \qquad x\in \Omega \\
            u(x)
	    &=& g(x) \qquad x\in \partial\Omega.
	\end{eqnarray*}
    mit $Lu = -\nabla \cdot (K\nabla u) + \nabla \cdot (cu) + qu$.

	Die FD-Diskretisierung mit $u_h\in V_h$ ist dann gegeben durch
	\begin{eqnarray*}
            L_h u_h
	    &=& f_h = I_h f \qquad x\in \Omega_h \\
            u_h
	    &=& g_h = I_h g \qquad x\in \partial\Omega_h \\
	\end{eqnarray*}
    mit
    \begin{eqnarray*}
            L_h u_h(x)
        &=& \sum_{i=1}^d \frac{1}{h^2} \biggl(K\left(x + \frac{h}{2} e^i\right)
            \left( u(x + h e^i) - u(x) \right) \\ 
            && + K\left(x - \frac{h}{2} e^i\right)\bigl(u(x)
               - u(x - h e^i) \bigr) \biggr) \\
            && + \sum_{i=1}^d  \frac{1}{h}  \big(c_i(x)
                 \left(u(x + h e^i)
               - u(x - h e^i)\right)\big) \\
            && + (\nabla c(x) + q(x)) u(x).
    \end{eqnarray*}
\end{enumerate}


\begin{Beispiel}[$d = 2$]
    Der Differenzenoperator lässt sich durch sogenannte
    \emph{Differenzensterne} darstellen, wobei hier $h_1 = h_2$ gewählt wurde.
    \begin{enumerate}[A)]
	\item
	    \emph{Laplace-Operator}: \\
	    Dieser lässt sich durch einen Fünfpunkte-
	    Differenzenstern dastellen:
	    \begin{eqnarray*}
              -\Delta_h
            = \frac{1}{h^2}
              \begin{bmatrix}
                  & & -1 & & \\
                  -1 & & 4 & & -1 \\
                  & & -1 & &
              \end{bmatrix},
	    \end{eqnarray*}
	    d.h
	    \begin{eqnarray*}
              -\Delta_h u_h(x)
            = \frac{1}{h^2} \left(4 u(x) - u\left(x + h e^1\right)
              - u\left(x - h e^1\right) - u\left(x + h e^2\right)
              - u\left(x - h e^2\right)\right).
	    \end{eqnarray*}
	\item
	    \emph{Konvektions-Diffusions-Operator}: \\
	    Der Operator
        $L u = -\nabla \cdot (K \nabla u) + \nabla \cdot (c u) + q u$
        kann auch durch einen Fünfpunkte-Diskretisierungsoperator
        dargestellt werden:
	    \begin{eqnarray*}
                L_h
            &=& \frac{1}{h^2} \left[
                \begin{smallmatrix}
                    & & -K\left(x - \frac{h}{2} e^2\right) & & \\
                    -K\left(x - \frac{h}{2} e^1\right) & &
                    K\left(x + \frac{h}{2} e^1\right)
                    + K\left(x + \frac{h}{2} e^1\right)
                    + K\left(x - \frac{h}{2} e^2\right)
                    + K\left(x - \frac{h}{2} e^2\right) & &
                    -K\left(x + \frac{h}{2} e^1\right) \\
                    & & -K\left(x - \frac{h}{2} e^2\right) & &
                \end{smallmatrix} \right] \\
		    &&+ \frac{1}{h} \left[
                \begin{smallmatrix}
                    & & c_2(x) & & \\
                    -c_1(x) & & 0 & & c_1(x) \\
                    & & -c_2(x) & &
                \end{smallmatrix} \right]
		    + \left[\begin{smallmatrix}
                  &  0 &  \\
                  0 & \nabla c(x) + q(x) & 0 \\
                  &  0 & \\
              \end{smallmatrix}\right],
	    \end{eqnarray*}
	    d.h.
	    \begin{eqnarray*}
            L_h u_h(x)
        &=& \sum_{i=1}^d \frac{1}{h^2} \biggl(K\left(x + \frac{h}{2} e^i\right)
            \left( u(x + h e^i) - u(x) \right) \\ 
            && + K\left(x - \frac{h}{2} e^i\right)\bigl(u(x)
               - u(x - h e^i) \bigr) \biggr) \\
            && + \sum_{i=1}^d  \frac{1}{h}  \big(c_i(x)
                 \left(u(x + h e^i)
               - u(x - h e^i)\right)\big) \\
            && + (\nabla c(x) + q(x)) u(x).
	    \end{eqnarray*}
    \end{enumerate}
\end{Beispiel}



\begin{Satz}
    \label{satz:2.2}
    Sei $K\in C^2(\overline\Omega), \ c\in C^1(\overline\Omega, \R^d), \
    q\in C(\overline\Omega)$ und $\Omega\subset \R^d$ offen. Sei dazu
    $\Omega_h = a + h \Z^d$ ein Gitter mit $x\pm he^i\in \overline\Omega$ für
    alle $x\in \Omega_h$. Dann gilt für alle $u\in C^4(\overline\Omega)$
    \begin{eqnarray*}
            \|L_h u - Lu\|_{\infty,\Omega_h}
        \le C h^2 \sum_{i=1}^d \left(\|\partial_i^4 u\|_{\infty, \Omega}
            + \|\partial_i^3 u\|_{\infty, \Omega}\right)
    \end{eqnarray*}
    (mit C unabhängig von h), d.h. $L_h$ ist konsistent von der Ordnung $p=2$.
\end{Satz}


\begin{proof}
    Es gilt
    \begin{eqnarray*}
            S^+_i
        &=& K\left(x + \frac{h}{2} e^i\right) \left(u\left(x + h e^i\right)
            - u(x)\right) \\
        &=& K\left(x + \frac{h}{2} e^i\right) \left(h\partial_i
            u\left(x + \frac{h}{2} e^i\right)
            + \frac{h^3}{6 \cdot 8}\partial_i^3
            u\left(x + \frac{h}{2} e^i\right) + O(h^5)\right),
        \\
            S^-_i
        &=& K\left(x - \frac{h}{2} e^i\right) \left(u(x)
            - u\left(x - h e^i\right)\right) \\
        &=& K\left(x - \frac{h}{2} e^i\right) \left(h\partial_i
            u\left(x - \frac{h}{2} e^i\right)
            + \frac{h^3}{6 \cdot 8}\partial_i^3
            u\left(x - \frac{h}{2} e^i\right) + O(h^5)\right).
    \end{eqnarray*}
    Mittels Taylorentwicklung von
    \begin{eqnarray*}
            u\left(x \pm \frac{h}{2}e^i\right)
        &=& u(x) \pm \frac{h}{2}\partial_i u(x)
            + \frac{h^2}{8}\partial_i^2 u(x) + O(h^3)
    \end{eqnarray*}
    ergibt sich
    \begin{eqnarray*}
        u\left(x + \frac{h}{2} e^i\right) - u\left(x - \frac{h}{2} e^i\right)
        = h \partial_i u(x) + O(h^3).
    \end{eqnarray*}
    Zusammen mit der Taylorentwicklung von
    \begin{eqnarray*}
            K\left(x \pm \frac{h}{2}e^i\right)
        &=& K(x) \pm \frac{h}{2}\partial_i K(x)
            + \frac{h^2}{8}\partial_i^2 K(x) + O(h^3)
    \end{eqnarray*}
    folgt dann
    \begin{eqnarray*}
            S^+_i - S^-_i
        &=& K(x) \left(h\partial_i \left(u\left(x + \frac{h}{2} e^i\right)
            - u\left(x - \frac{h}{2} e^i\right)\right)\right) \\
        &&  + \frac{h^3}{6 \cdot 8}\partial_i^3
            \left(u\left(x + \frac{h}{2} e^i\right)
            - u\left(x - \frac{h}{2} e^i\right)\right) \\
        &&    + \frac{h}{2}\partial_i K(x)
            \left(h\partial_i \left(u\left(x + \frac{h}{2} e^i\right)
            - u\left(x - \frac{h}{2} e^i\right)\right)\right)
            + O(h^4) \\
        &=& h^2 K(x) \partial_i^2 u(x) + \frac{h^3}{2} \partial_i K(x)
            \partial_i^2 u(x) + O(h^4).
    \end{eqnarray*}
    Analog zur obigen Taylorentwicklung gilt
    \begin{eqnarray*}
        u\left(x + h e^i\right) - u\left(x - h e^i\right)
        = 2 h \partial_i u(x) + O(h^3).
    \end{eqnarray*}
    Dies liefert uns schlie\ss{}lich
    \begin{eqnarray*}
            |L_h u(x) - Lu(x)|
        &=& \Biggl|\sum_{i=1}^d \Biggl[\frac{1}{h^2} \left(K(x) h^2
            \partial_i^2 u(x)
            - \partial_i K(x) \frac{h^3}{2} \partial_i u(x)\right) \\
            &&+ \frac{1}{h} (c_i(x) 2 h \partial_i u(x))\Biggr]
            + K(x) \Delta u(x) \\
            &&+ \nabla K(x) \nabla u(x) - c(x) \nabla u(x) + O(h^2)\Biggr|
         =  O(h^2)
    \end{eqnarray*}
    Konsistenz der Ordnung $p = 2$.
\end{proof}


\begin{Implementation}
    Sei $\Omega_h = \left\{x^1, \dots, x^N\right\}$ mit $N = N_1 N_2$ eine
    Nummerierung der Gitterpunkte und
    \begin{eqnarray*}
          V_h(0)
        = \{u_h\in V_h \colon u_h(x) = 0 \text{ für } x\in \partial\Omega_h\}.
    \end{eqnarray*}
    Weiter sei
    \begin{eqnarray*}
        E_h \colon \R^N &\to& V_h(0) \\
        \underline u &\mapsto& u_h \qquad \text{mit } u_h(x^n)
        = \underline u_n.
    \end{eqnarray*}
    Dann definiere $u_h^g\in V_h$ mit
    \begin{eqnarray*}
        u_h^g(x) &=& g(x) \quad x\in \partial\Omega_h \\
        u_h^g(x) &=& 0 \quad \ \quad x\in \Omega_h.
    \end{eqnarray*}
    Bestimme $u_h^0 = E_h\underline u$ mit
    \begin{eqnarray*}
        L_h \left(u_h^0 + u_h^g\right)(x) = f(x) \quad \Leftrightarrow \quad
        L_h u_h^0 = f_h - L_h u_h^g.
    \end{eqnarray*}
    Dann ist $u_h = u_h^0 + u_h^g$ Lösung.
\end{Implementation}


\begin{Beispiel}
    Sei $\Omega = (a_1, b_1) \times (a_2, b_2)$ und $h_1 = h_2 = h$. \\
    Die lexikographische Nummerierung ist definiert durch
    \begin{eqnarray*}
        x^{(j - 1) N_2 + k} = x_{j k} = \begin{pmatrix}
                                          a_1 + jh \\
                                          a_2 + kh
                                        \end{pmatrix},
        \qquad \text{schreibe } \underline u_{j k} \text{ statt }
        \underline u_n.
    \end{eqnarray*}
    Gesucht ist eine Lösung $u_h$ des Poisson-Problems:
    \begin{eqnarray*}
        -\Delta_h u_h &=& f \qquad \text{in } \Omega_h \\
        u_h &=& g \qquad \text{auf } \partial\Omega_h.
    \end{eqnarray*}
    Setzte dazu $u_h = u_h^0 + u_h^g$ mit $u_h^0(x^n) = \underline u_n$.

    Aus $-\Delta_h u_h = -\Delta_h (u_h^0 + u_h^g) = f$ folgt somit
    $-\Delta_h u_h^0 = f + \Delta_h u_h^g$.

    Für das Poisson-Problem gilt für die inneren Gitterpunkte
    \begin{eqnarray*}
        \frac{1}{h^2} (- u_h(x_{n-1, j}) - u_h(x_{n+1, j}) + 4 u_h(x_{n j})
        - u_h(x_{n, j-1}) - u_h(x_{n, j+1})) = f(x_{n j}) \\
        (1 \le n \le N_1, \ 1 \le j \le N_2)
    \end{eqnarray*} 
    und den Randpunkten
    \begin{eqnarray*}
        u_h(x_{n j}) = g(x_{n j})
        \qquad (n\in \{0, N_1 + 1\} \text{ oder } j\in \{0, N_2 + 1\}).
    \end{eqnarray*}
    Dies führt uns zu den Gleichungen
    \begin{eqnarray*}
          \frac{1}{h^2} (4 \underline u_{1 1} - \underline u_{1 2}
          - \underline u_{2 1})
        = \underline f_{1 1} + \frac{1}{h^2} (\underline g_{0 1}
          + \underline g_{1 0})
        &= \colon& \underline{\hat{f}}_{1 1}, \\
          \frac{1}{h^2} (4 \underline u_{k 1} - \underline u_{k-1,1}
          - \underline u_{k 2})
        = \underline f_{k 1} + \frac{1}{h^2} \underline g_{k 0}
        &= \colon& \underline{\hat{f}}_{k 1}, \\
          \qquad (k = 2, \dots, N_1 - 1) \\
          \frac{1}{h^2} (4 \underline u_{N_1 1} - \underline u_{N_1 2}
          - \underline u_{N_1-1,1})
        = \underline f_{N_1 1} + \frac{1}{h^2} (\underline g_{N_1 0}
          + \underline g_{N_1+1,0})
        &= \colon& \underline{\hat{f}}_{N_1 1}, \\
          \frac{1}{h^2} (4 \underline u_{j k} - \underline u_{j-1,k}
          - \underline u_{j+1,k} - \underline u_{j,k+1} - \underline u_{j,k-1})
        = \underline f_{j k}
        &= \colon& \underline{\hat{f}}_{j k}, \\
          \qquad (2 \le j \le N_1 - 1, \ 2 \le k \le N_2 - 1) \\
        &\vdots&
    \end{eqnarray*}
    Durch sukzessives fortführen erhalten wir dadurch für das Poisson-Problem
    folgendes LGS
    $\underline A \underline u = \underline{\hat{f}} \in \R^N$ mit
    \begin{eqnarray*}
        \underline A = \frac{1}{h^2}
                       \begin{pmatrix}
                          T & -I & & & & & \\
                          -I & T & -I & & & & \\
                          & \ddots & \ddots & \ddots & & & \\
                          \\
                          \\
                          & & & & -I & T & -I \\
                          & & & & & -I & T
                       \end{pmatrix}
        \in \R^{N_1 N_2, N_1 N_2},
    \end{eqnarray*}
    wobei
    \begin{eqnarray*}
        T &=& tridiag(-1, 4, -1) \in \R^{N_1, N_1}, \\
        I &=& diag(1, \cdots, 1) \in \R^{N_1, N_1}.
    \end{eqnarray*}
\end{Beispiel}


\begin{Definition}
    \label{def:2.3}
    $A \in \R^{N, N}$ heißt
    \begin{enumerate}[a)]
	\item
	    irreduzibel, wenn der Matrix-Graph
	    \begin{eqnarray*}
            G(A) = \{(n, k) \colon A[n, k] \neq 0\}
	    \end{eqnarray*}
	    zusammenhängend ist.
	\item
	    stark diagonal-dominant, wenn
	    \begin{eqnarray*}
            |A[n, n]| \ge \sum_{k=1, k\neq n}^N |A[n, k]|, \quad n = 1, \cdots,
            N \\
	    \end{eqnarray*}
	    und ein $j \in \{1, \cdots, N\}$ existiert mit
	    \begin{eqnarray*}
            |A[j, j]| > \sum_{k=1, k\neq j}^N |A[j, k]|.
	    \end{eqnarray*}
	\item
	    M-Matrix, wenn
	    \begin{enumerate}[i)]
          \item
              $A[n, n] > 0$ für $n = 1, \cdots, N$, \\
              $A[n, k] \le 0$ für $n \neq k$.
          \item
              $A$ invertierbar und $A^{-1}[n, k] \ge 0$, für
              $n, k = 1, \cdots, N$.
	    \end{enumerate}
    \end{enumerate}
\end{Definition}


\begin{Satz}
    \label{satz:2.3}
    Wenn $A\in \R^{N, N}$ eine irreduzible, stark diagonal dominante Matrix mit
    strikt positiven Diagonalelementen und negativen Nebendiagonalen ist, dann
    ist $A$ eine M-Matrix.
\end{Satz}


\begin{Anwendung}
    \begin{enumerate}[A)]
	\item
	    Die Fünfpunkte-Diskretisierung des Laplace-Operators
	    \begin{eqnarray*}
            -\Delta_h = \begin{bmatrix}
                    & & -1 & & \\
                    -1 & & 4 & & -1 \\
                    & & -1 & &
                        \end{bmatrix}
	    \end{eqnarray*}
	    ist eine M-Matrix mit Konsistenzordnung $p = 2$.

        Für die Randpunkte $x - h e^1 \in \partial\Omega_h$ und
        $x - h e^1, x - h e^2 \in \partial\Omega_h$ sind die Differnezensterne
        \begin{eqnarray*}
            \begin{bmatrix}
                & & -1 & & \\
                0 & & 4 & -1 \\
                & & -1 & &
            \end{bmatrix}
            \quad \text{und} \quad
            \begin{bmatrix}
                & & -1 & & \\
                0 & & 4 & -1 \\
                & & 0 & &
            \end{bmatrix}.
        \end{eqnarray*}
	\item
	    Der Differentialoperator $Lu = -\nabla \cdot (K \nabla u)$ mit
	    $K(x) > 0$ lässt sich durch die Fünfpunk- te-Diskretisierung
	    \begin{eqnarray*}
              L_h
            = \frac{1}{h^2} \left[
              \begin{smallmatrix}
                  & & -K\left(x - \frac{h}{2} e^2\right) & & \\
                  - K\left(x - \frac{h}{2} e^1\right) & &
                  K\left(x + \frac{h}{2} e^1\right)
                  + K\left(x + \frac{h}{2} e^1\right)
                  + K\left(x - \frac{h}{2} e^2\right)
                  + K\left(x - \frac{h}{2} e^2\right) & &
                  -K\left(x + \frac{h}{2} e^1\right) \\
                  & & -K\left(x - \frac{h}{2} e^2\right) & &
              \end{smallmatrix} \right]
	    \end{eqnarray*}
	    darstellen, die eine M-Matrix ist und Konsistenzordnung $p = 2$ hat.
	\item
	    Nun sei $Lu = - \sum_{i, j=1}^2 K_{ij}(x) \partial_i \partial_j u$,
	    mit $K_{ij} \in \R$ und $K_{12} = K_{21}$. Der Neunpunkte-
	    Diskretisierungsoperator
	    \begin{eqnarray*} 
              L_h
            = \frac{1}{h^2}
              \begin{bmatrix}
                  -\frac{1}{2} K_{12}(x) & -K_{22}(x) & \frac{1}{2} K_{12}(x) \\
                  -K_{11}(x) & 2 K_{11}(x) + 2 K_{22}(x) & - K_{11}(x) \\
                  \frac{1}{2} K_{12}(x) & -K_{22}(x) & -\frac{1}{2} K_{12}(x)
              \end{bmatrix}
	    \end{eqnarray*}
	    ist konsistent der Ordnung $p = 2$, aber keine M-Matrix.
	\item
	    Wir setzen $K_{12} = K_{12}^+ - K_{12}^-$ und
	    $K_{12}^+ = \max \{K_{12}, 0\} \ge, \
	    K_{12}^- \max \{K_{12}, 0\} \le 0$. Dann ist für
	    $Lu = - \sum_{i, j=1}^2 K_{ij}(x) \partial_i \partial_j u
	    + \sum_{i=1}^2 c_i \partial_i u$ der diskrete Laplace-Operator
	    \begin{eqnarray*}
              L_h
            = \frac{1}{h^2}\left[
              \begin{smallmatrix}
                  K_{12}^- & & -K_{22} + |K_{12}| & & -K_{12}^+ \\
                  -K_{11} + |K_{12}| & & 2 (|K_{12}| + K_{11} + K_{22})
                  & & -K_{11} +|K_{12}| \\
                  -K_{12}^+ & & -K_{22} + |K_{12}| & & K_{12}^-
              \end{smallmatrix}\right]
            + \frac{1}{h}\left[
              \begin{smallmatrix}
                  & & -c_2^+ & & \\
                  c_1^- & & |c_1| + |c_2| & & -c_1^+ \\
                  & & c_2^- & &
              \end{smallmatrix}\right]
	    \end{eqnarray*}
	    eine M-Matrix falls $|K_{12}| < K_{11}$ und $|K_{12}| < K_{22}$.
	    Es handelt sich jedoch nur um eine Diskretisierung der Konsistenzordnung
        $p = 1$.
	\item
	    Sei $x \in \{a_1\} \times (a_2, b_2) \cap \partial \Omega_h$.
	    Dann gilt für $-\Delta u = f$ mit den Neumann-Randbedingungen
	    $\nu \nabla u = \partial_\nu u = g$, dass der
	    diskrete Laplace-Operator
	    \begin{eqnarray*}
            -\Delta_h = \frac{1}{h^2}
                        \begin{bmatrix}
                            & -1 & \\
                            0 & 3 & -1 \\
                            & -1 &
                        \end{bmatrix}
	    \end{eqnarray*}
	    eine M-Matrix ist, falls mindestens ein Punkt $x \in \partial
	    \Omega_h$ Dirichlet-Randbedingungen hat und konsistent von der
	    Ordunung $p=2$ ist.
    \end{enumerate}
\end{Anwendung}


\begin{Diskretisierungen hoher Ordnung}
    \begin{enumerate}[A)]
	\item
	    Der Neunpunkte-Diskretisierungsoperator
	    \begin{eqnarray*}
            -\Delta_h = \frac{1}{12 h^2}
                        \begin{bmatrix}
                            & & 1 & & \\
                            & & -16 & & \\
                            1 & -16 & 60 & -16 & 1 \\
                            & & -16 & & \\
                            & & 1 & &
                        \end{bmatrix}
	    \end{eqnarray*}
	    ist bei periodischem Rand konsistent von der Ordnung $p = 4$, aber keine
        M-Matrix.
	\item
	    Es gibt keine Neunpunkte-Operatoren mit
	    $\Delta_h u - \Delta u = O(h^3)$. \\
	    Aber $-\Delta_h u = R_h f$ mit
	    \begin{eqnarray*}
            \Delta_h =  \frac{1}{6 h^2}
                        \begin{bmatrix}
                            -1 & -4 & -1 \\
                            -4 & 20 & -4 \\
                            -1 & -4 & -1
                        \end{bmatrix},
            \qquad
            R_h = \frac{1}{6}
                  \begin{bmatrix}
                      & -\frac{1}{2} & \\
                      -\frac{1}{2} & 4 & -\frac{1}{2} \\
                      & -\frac{1}{2} &
                  \end{bmatrix},
	    \end{eqnarray*}
	    erfüllt
	    \begin{eqnarray*}
              -\Delta_h u
            = -\Delta u - \frac{h^2}{12} \Delta^2 u + O(h^4), \\
              R_h f
            = f + \frac{h^2}{12} \Delta f + O(h^4), \\
              -\Delta u - \frac{h^2}{12} \Delta^2 u = f + \frac{h^2}{12}
              \Delta f.
	    \end{eqnarray*}
	    Somit ist das Verfahren konsistent von der Ordnung $p = 4$. Insbesondere
        ist $R_h$ eine M-Matrix.
    \end{enumerate}
\end{Diskretisierungen hoher Ordnung}


\begin{Bemerkung}
    Für das Laplace-Problem ($f = 0$) gilt sogar Konsistenzordnung $p = 6$.
\end{Bemerkung}


\begin{Implementation}
    Der Raum der inneren Gitterpunkte und der Randpunkte sei
    \begin{eqnarray*}
          \Omega_h
        &=& (a + h \Z^d) \cap \Omega \qquad \text{ mit } x \pm h e^i
            \in \partial\Omega, \\
          \partial\Omega_h
        &=& (a + h \Z^d) \cap \partial\Omega.
    \end{eqnarray*}
    Die Gesamtheit aller Gitterpunkte ist dann
    \begin{eqnarray*}
        \overline\Omega_h = \Omega_h \cup \partial\Omega_h.
    \end{eqnarray*}
    Weiter sei der Raum der Gitterfunktionen 
    $V_h = \left\{u_h: \overline\Omega_h \to \R\right\}$ und die Räume der Gitterfunktionen die an den Randpunkten Werte einer Funktion $g: \Omega \to \R$ annehmen, sei
    \begin{eqnarray*}
          V_h(g)
        &=& \{u_h \in V_h: u_h(x) = g(x), \ x \in \partial \Omega_h\}.
    \end{eqnarray*}
    Der Raum der Funktionen auf den inneren Gitterpunkten wird mit $V_h^\prime = \{u_h: \Omega_h \to \R\}$ bezeichnet.

    Der diskrete Operator und die Gitterinterpolation seien definiert durch
    \begin{eqnarray*}
        L_h: V_h &\to& V_h^\prime, \\
        I_h: C(\overline\Omega) &\to& V_h, \quad u \mapsto (u(x))_{x\in \overline\Omega_h}.
    \end{eqnarray*}
    Definiere $u_h^g \in V_h$ mit
    \begin{eqnarray*}
        u_h^g(x) &=& g(x) \qquad x\in \partial\Omega_h \\
        u_h^g(x) &=& 0 \quad \ \qquad x\in \Omega_h.
    \end{eqnarray*}
    Dann löst $u_h = u_h^0 + u_h^g \in V_h(g)$ mit $u_h^0 \in V_h(0)$
    \begin{eqnarray*}
        L_h u_h = f \quad \Leftrightarrow \quad
        L_h u_h^0 = \underline f - L_h u_h^g =: \underline{\hat{f}}.
    \end{eqnarray*}
    Sei $\Omega_h = \left\{x^1,\dots,x^N\right\}$ eine lexikographische
    Nummerierung
    $(x^n = x_{jk} \text{ mit } n = (j - 1) N_2 + k)$.
    Eine Nummerierung der Gitterpunkte wird dann definiert durch
    \begin{eqnarray*}
        E_h: \R^N &\to& V_h(0), \\
        \underline u &\mapsto& u_h \in V_h(0)
        \qquad \text{mit } u_h(x^n) = \underline u_n \\
        E_h^\prime: V_h^\prime &\to& \R^N \\
        f &\mapsto& \underline f = (f(x^n))_{n=1,\dots,N}.
    \end{eqnarray*}
    Also definiere $\underline A\in \R^{N,N}$ mit
    $\underline A = E_h^\prime L_h E_h$.
\end{Implementation}


\begin{Definition}
    \label{def:2.5}
    Sei $L \colon C^2(\Omega) \cap C(\overline\Omega) \to C(\Omega)$ ein
    Differenzenoperator 2. Ordnung. Sei $L_h \colon V_h \rightarrow V_h^{'}$ eine
    FD-Approximation. Dann heißt $L_h$
    \begin{enumerate}[a)]
	\item
	    konsistent von der Ordnung $p$, wenn für hinreichend glatte
	    $u$
	    \begin{eqnarray*}
            \|I_h L u -L_h I_h u\|_{\infty, \Omega_h} \le h^p C(u).
	    \end{eqnarray*}
	\item
	    konvergent von der Ordnung $p$, wenn (für hinreichend glatte
	    $u$) und $u_h \in V_h$ mit
	    \begin{eqnarray*}
            L_h u_h &=& L u \qquad \text{für } x \in \Omega_h \\
            u_h &=& u \ \ \qquad \text{für } x \in \partial \Omega_h
	    \end{eqnarray*}
	    gilt
	    \begin{eqnarray*}
            \|I_h u - u_h\|_{\infty, \Omega_h} \le h^p C(u).
	    \end{eqnarray*}
	\item
	    stabil, wenn $\tilde C > 0$ (unabhängig von $h$) existiert,
	    sodass für alle $v_h \in V_h(0)$ gilt
	    \begin{eqnarray*}
                \|v_h\|_{\infty, \Omega_h}
            \le \tilde C \|L_h v_h\|_{\infty, \Omega_h}.     
	    \end{eqnarray*}
    \end{enumerate} 
\end{Definition}


\begin{Bemerkung}
    Die Stabilität hängt von den Randbedingungen ab.
\end{Bemerkung}


\begin{Satz}
    \label{satz:2.6}
    Sei $L_h$ stabil und konsistent (von der Ordnung $p$). Dann ist $L_h$
    konvergent (von der Ordnung $p$).
\end{Satz}


\begin{proof}
    Es gilt
    \begin{eqnarray*}
            \|I_h u - u_h\|_{\infty, \Omega_h}
        &=& \|\underbrace{L_h^{-1} L_h (I_h u - u_h)}_{= \colon v_h}\|
            _{\infty, \Omega_h} \\
        &\le& \tilde C \|L_h (I_h u - u_h)\|_{\infty, \Omega_h} \\
        &\le& \tilde C C(u) h^p.
    \end{eqnarray*}
    Die FD-Approximation ist konvergent von der Ordnung $p$.
\end{proof}


\begin{Definition}
    \label{def:2.7}
    Der Finite-Differenzen-Operator $L_h \colon V_h \rightarrow V_h^\prime$
    heißt \emph{invers monoton}, wenn für
    \begin{eqnarray*}
        L_h v_h(x) &\ge& 0 \qquad x \in \Omega_h \\
        v_h(x) &\ge& 0 \qquad x \in \partial \Omega_h
    \end{eqnarray*}
    dann auch $v_h(x) \ge 0$ für alle $x \in \Omega_h$ gilt.
\end{Definition}


\begin{Beispiel}
    \begin{enumerate}[A)]
	\item
	    Sei $\underline A = E_h^\prime L_h E_h$ M-Matrix und $-L_h u_h^g
	    \ge 0$ für $g \ge 0$. Dann gilt wenn $\underline A
	    \underline u \ge 0$, ist auch $\underline A^{-1}
	    (\underline A \underline u) \ge 0$. Also $\underline u \ge
	    0$ und $L_h$ somit invers monoton.
	\item
	    Direkter Beweis der inversen Monotonie für den
        Fünfpunkte-Differenzenoperator
	    \begin{eqnarray*}
            L_h = -\Delta_h = \frac{1}{h^2}
                  \begin{bmatrix}
                      & -1 & \\
                      -1 & 4 & -1 \\
                      & -1 &
                  \end{bmatrix}.
	    \end{eqnarray*}
        Wir zeigen dafür folgende Aussage:

	    Sei $\Omega = (a_1, b_1) \times (a_2, b_2)$ und
	      $\mathcal{V}
	    = \left\{\left(\begin{smallmatrix} a_1 \\ a_2 \end{smallmatrix}\right),
            \left(\begin{smallmatrix} b_1 \\ a_2 \end{smallmatrix}\right),
            \left(\begin{smallmatrix} a_1 \\ b_2 \end{smallmatrix}\right),
            \left(\begin{smallmatrix} b_1 \\ b_2 \end{smallmatrix}\right)
          \right\}$ die Menge aller Eckpunkte.
	    Dann gilt falls $\Delta_h u_h \ge 0$ in $\Omega_h$:
	    \begin{eqnarray*}
            \max_{x \in \overline \Omega_h \backslash \mathcal{V}} u_h(x) =
            \max_{x \in \partial \Omega_h \backslash \mathcal{V}} u_h(x).
	    \end{eqnarray*}
	    \begin{proof}
            Annahme: Es existiert ein $y \in \Omega_h$ mit $u_h(y) =
            \max_{x \in \overline \Omega_h \backslash \mathcal{V}} u_h(x)
            = \overline u$.

            Behauptung: Dann ist $u_h \equiv \overline u$.

            Es gilt
            \begin{eqnarray*}
                    \Delta_h u_h(y)
                &=& \frac{1}{h^2} \bigl(u_h \left(y - h e^1\right)
                    + u_h \left(y + h e^1\right) + u_h \left(y - h e^2\right)
                    + u_h \left(y + h e^2\right) \\
                    &&- 4 u_h(y)\bigr) \ge 0.
            \end{eqnarray*}
            Und damit
            \begin{eqnarray*}
                      4 \overline u = 4 u_h(y)
                &\le& u_h \left(y + h e^1\right) + u_h\left(y - h e^1\right)
                      + u_h \left(y + h e^2\right) + u_h\left(y - h e^2\right) \\
                &\le& 4 u_h(y) = 4 \overline u.
            \end{eqnarray*}
            Demnach erfüllen alle Nachbarn
            $u_h(y) = u_h\left(y \pm h e^i\right) \equiv \overline u$.
	    \end{proof}
        Entweder ist $u_h \equiv$ const. oder $u_h(y) < \max_{x\in
        \partial\Omega_h \backslash \mathcal{V}} u_h(x)$ für alle $y\in
        \Omega_h$.

	    Also wenn
	    \begin{eqnarray*}
            -\Delta_h (-v_h) &\ge& 0 \qquad x \in \Omega_h \\
            -v_h &=& 0 \qquad x \in \partial \Omega_h 
	    \end{eqnarray*}
	    dann folgt $-v_h \le 0$ und somit $v_h \ge 0$. Das bedeutet
	    $-\Delta_h$ ist \emph{invers monoton}.
    \end{enumerate}
\end{Beispiel}


\begin{Satz}
    \label{satz:2.8}
    Sei $L_h$ invers monoton und für ein $w_h \in V_h$ gelte
    \begin{eqnarray*}
        L_h w_h &\ge& 1 \qquad x \in \Omega_h \\
        w_h &\ge& 0 \qquad x \in \partial \Omega_h.
    \end{eqnarray*}
    Dann gilt
    \begin{eqnarray*}
            \|v_h\|_{\infty, \Omega_h}
        \le \tilde C \|L_h v_h\|_{\infty, \Omega_h}
    \end{eqnarray*}
    für alle $v_h \in V_h(0)$ mit $\tilde C = \|w_h\|_{\infty, \Omega_h}$.
\end{Satz}


\begin{proof}
    Sei $\alpha = \|L_h v_h\|_{\infty, \Omega_h}$ und $u_h = \alpha w_h -
    v_h$. Dann ist
    \begin{eqnarray*}
        L_h u_h = \alpha L_h w_h - L_h v_h \ge \alpha - L_h v_h &\ge& 0
        \qquad x \in \Omega_h \\
        u_h = \alpha w_h - v_h &\ge& 0 \qquad x \in \partial \Omega_h.
    \end{eqnarray*}
    Da $L_h$ invers monoton ist $u_h \ge 0$ für alle $x\in \Omega_h$ und somit
    $\alpha w_h \ge v_h$ für alle $x\in \Omega_h$. Damit folgt schlie\ss{}lich
    \begin{eqnarray*}
        \|L_h v_h\|_{\infty, \Omega_h} \|w_h\|_{\infty, \Omega_h} =
        \|\alpha w_h\|_{\infty, \Omega_h} \ge \|v_h\|_{\infty, \Omega_h}
    \end{eqnarray*}
    die Stabilität der FD-Approximation.
\end{proof}


\begin{Beispiel}
    Zu $\Omega = (a_1, b_1) \times (a_2, b_2)$ betrachte
    \begin{eqnarray*}
     	  w(x)
        = \frac{1}{4} (x_1 - a_1) (b_1 - x_1) + \frac{1}{4} (x_2 - a_2)
          (b_2 - x_2).
    \end{eqnarray*}
    Dann ist $w(x) \ge 0 \text{ und } -\Delta w(x) \equiv 1 \text{ für alle }
    x\in \overline\Omega$. Nach der Konsistenzabschätzung für den diskreten
    Laplace-Operator gilt
    \begin{eqnarray*}
        \|\Delta w - \Delta_h I_h w\|_{\infty, \Omega_h} \le C h^2
        \left(\|\partial_1^4 w\|_\infty + \|\partial_2^4 w\|_\infty\right)
    \end{eqnarray*}
    mit $w_h(x) = I_h w(x)$. Da $w(x)$ quadratisch ist gilt $\partial_1^4 w(x)
    = \partial_2^4 w(x) \equiv 0$ für $x\in \Omega$ und somit $\Delta w(x) =
    \Delta_h w_h(x)$ auf $\Omega_h$. Damit gilt $w_h(x) \ge 0 \text{ und }
    -\Delta_h w_h(x) \equiv 1 \text{ für } x\in \overline\Omega_h$.
    Die Stabilitätskonstante ist dann nach $\eqref{satz:2.8}$
    \begin{eqnarray*}
        \tilde C = \|w_h\|_{\infty, \Omega_h} =
        \frac{1}{16} \left((b_1 - a_1)^2 + (b_2 - a_2)^2\right).
    \end{eqnarray*}
\end{Beispiel}


\begin{Bemerkung}
    Wenn $u \in C^4(\overline\Omega)$, dann gilt
    $\|u_h - I_h u\|_{\infty, \Omega_h}
    \le \frac{(b_1 - a_1)^2 + (b_2 - a_2)^2}{192} h^2
    \left(\|\partial_1^4 u\|_\infty + \|\partial_2^4 u\|_\infty\right)$.
\end{Bemerkung}


\subsection{Verallgemeinerung und Grenzen von FD}


\begin{enumerate}[A)]
    \item
	Allgemeine Gebiete $\Omega \subset \R^2$:

	Sei $x \in \Omega_h = h \Z^2 \cap \Omega$ und $x + h e^i \not\in \Omega$.

	Wähle $\vartheta \in (0, 1]$ mit $x + s h e^i \in \Omega$ für
    $s \in [0, \vartheta)$ und $x + \vartheta h e^i \in \partial \Omega$.

	Für die Approximation eines solchen Randpunktes gilt
	\begin{eqnarray*}
          \partial_i^2 u(x)
        = &\frac{2}{h_1 + h_2} \left(\frac{1}{h_1}
           \left(u\left(x + h_1 e^i\right) - u(x)\right)
            - \frac{1}{h_2} \left(u(x) - u\left(x - h_2 e^i\right)\right)\right)
          \\
          &+ O(h)
	\end{eqnarray*}
	mit $h = \max\{h_1, h_2\}$. Dann lässt sich die FD-Diskretisierung
	darstellen durch
	\begin{eqnarray*}
          -\Delta_h
	    = \begin{bmatrix}
		  & -1 & \\
		  -1 & 3 + \frac{2}{(1 + \vartheta) \vartheta}
		  & -\frac{2}{(1 + \vartheta) \vartheta} \\
		  & -1 &
	      \end{bmatrix}.
	\end{eqnarray*}
\end{enumerate}


\begin{Bemerkung}
    Es existiert zu $h_1 \neq h_2$ keine $\alpha, \ \beta, \gamma$ mit
    \begin{eqnarray*}
          \partial_i^2 u(x)
        = \alpha u(x) + \beta u\left(x - h_1 e^i\right)
          + \gamma u\left(x + h_2 e^i\right) + O(h_1^2) + O(h_2^2).
    \end{eqnarray*}
\end{Bemerkung}


\begin{enumerate}[B)]
    \item
	Regularität:
	\begin{enumerate}[i)]
	    \item
		Betrachte in $\Omega = (0, b_1) \times (0, b_2)$
		\begin{eqnarray*}
		    -\Delta u &=& 1 \qquad \text{in } \Omega \\
		    u &=& 0 \qquad \text{auf } \partial\Omega.
		\end{eqnarray*}
		Dann gilt $\partial_1^2 u(0) = \partial_2^2 u(0) = 0$
		und es folgt $\Delta u(0) = 0$.

        Damit ist $\Delta u \in C(\Omega)$, aber
		$\Delta u\not\in C(\overline \Omega)$ und somit ist
        $u\not\in C^2(\overline\Omega)$.
	    \item
		Wir betrachten nun auf $\R^2$ ein Gebiet mit einspringender Ecke.
        Dies sei definiert durch
        $\Omega = \{x\in \R^2: |x| < 1, \ x_1 < 0 \text{ oder } x_2 > 0\}$.

        Wählen wir dazu $w(z) =  z^\frac{2}{3}$ für
        $z\in \C$, also $w \in H(\C \backslash S_-)$, und identifizieren $\R^2$ mit $\C$, dann ist
        \begin{eqnarray*}
            u(x) = \Im w(x_1 + i x_2) = r^\frac{2}{3} \sin\left(\frac{2}{3}
            \varphi\right),
        \end{eqnarray*}
        da $w$ holomorph für $z \neq 0$, Lösung der PDE
		\begin{eqnarray*}
		    -\Delta u &=& 0 \qquad \text{in } \Omega \\
		    u &=& g \qquad \text{auf } \partial\Omega
		\end{eqnarray*}
		mit
		\begin{eqnarray*}
		    g(x) &=& \sin\left(\frac{2}{3} \varphi\right) \qquad \ \text{für }
                      x\in \partial\Omega, \ |x| = 1 \\
		    g(x) &=& 0 \qquad \qquad \qquad \text{für } x \in \partial\Omega,
                    \ |x| < 1.
		\end{eqnarray*}
		Wenn wir nun ein $x_0 \in \partial \Omega$ mit $|x_0| = 1$ wählen,
        dann gilt
		\begin{eqnarray*}
		    \lim_{r \to 0} |\nabla u(r x_0)| \ge \lim_{r \to 0}
		    \left|\frac{\mathrm d}{\mathrm d r} r^\frac{2}{3}\right| =
            \lim_{r \to 0} \frac{2}{3} r^{-\frac{1}{3}} = \infty.
		\end{eqnarray*}
        Im einspringenden Eckpunkt ist $\nabla u$ nicht mehr beschränkt und
        somit $u \not\in C^1(\overline\Omega)$.
	\end{enumerate}
\end{enumerate}


\subsection{Schnelle direkte Löser für das Poisson-Problem}


\begin{Definition}
    Seien $B \in \R^{N_1, N_2}, \ C \in \R^{N_3, N_4}$. Dann heißt die
    Blockmatrix
    \begin{eqnarray*}
	B \otimes C = \begin{pmatrix}
                      B[1, 1]C & \cdots & B[1, N_2]C \\
                      \vdots & & \vdots \\
                      B[N_1, 1]C & \cdots & B[N_1, N_2]C
	              \end{pmatrix} \in \R^{N_1 N_3, N_2 N_4}
    \end{eqnarray*}
    das \emph{Kronecker-Produkt} von $B$ und $C$.
\end{Definition}


\begin{Beispiel}
    Definiere $T_N = tridiag(-1, 2, -1), \ I_N \in \R^{N, N}$.
    Für den Fünfpunkte-Stern gilt
    \begin{eqnarray*}
            A
        &=& I_{N_1} \otimes T_{N_2} + T_{N_1} \otimes I_{N_2} \\
        &=& \begin{bmatrix}
                T_{N_2} \\
                & \ddots \\
                \\
                \\
                & & & & & T_{N_2}
            \end{bmatrix}
         +  \begin{bmatrix}
                2 I_{N_2} & -I_{N_2} \\
                -I_{N_2} & \ddots & \ddots \\
                & \ddots \\
                & & & -I_{N_2} \\
                & & -I_{N_2} & 2 I_{N_2}
            \end{bmatrix} \\
        &=& \begin{bmatrix}
                T & -I_{N_2} \\
                -I_{N_2} & \ddots & \ddots \\
                & \ddots \\
                \\
                & & & & -I_{N_2} \\
                & & & I_{N_2} & T
            \end{bmatrix}
        \in \R^{N_1 N_2, N_1 N_2},
    \end{eqnarray*}
    wobei $T = T_{N_2} + 2 I_{N_2} = tridiag(-1, 4 , -1)$.
\end{Beispiel}


\paragraph{Matrix-Kalkül für Kronecker-Produkte}


\begin{enumerate}[a)]
    \item
      Seien
      $B_1 \in \R^{N_1, N_2}, \ B_2 \in \R^{N_2, N_3}, \ C_1 \in\R^{N_4, N_5},
      \ C_2 \in \R^{N_5, N_6}$.
      Dann gilt
      \begin{eqnarray*}
          (B_1 \otimes C_1) (B_2 \otimes C_2) = (B_1 B_2) \otimes
          (C_1 C_2) \in \R^{N_1 N_4, N_3 N_6}.
      \end{eqnarray*}
    \item
      Seien $q^n \ (n = 1, \cdots, N_1)$ und $p^k \ (k = 1, \cdots, N_2)$ Basen
      von $\R^{N_1}$ bzw. $\R^{N_2}$. Dann ist $\{q^n \otimes p^k : n=1,\dots,N_1,\ k=1,\dots,N_2\}$ Basis von
      $\R^{N_1, N_2}$.
    \item
      Seien $e^n_{N_1}, \ e^k_{N_2}$ die Einheitsvektoren in $\R^{N_1}$ bzw.
      $\R^{N_2}$.
      Dann gilt für $B \in \R^{N_1, N_2}$
      \begin{eqnarray*}
          B = \sum_{n=1}^{N_1} \sum_{k=1}^{N_2} B[n, k] \left[e^n_{N_1}
          \otimes \left(e^k_{N_2}\right)^T\right].
      \end{eqnarray*}
    \item
      Seien $B \in \R^{N_1, N_2}, \ C \in \R^{N_3, N_4}, \ x \in \R^{N_2 N_4}$.
      Dann ist $y = (B \otimes C) x \in \R^{N_1 N_3}$, genau dann wenn
      $Y = BXC^T$ mit
      \begin{eqnarray*}
          X = \begin{pmatrix}
                x_1 & \cdots & x_{N_4} \\
                x_{N_4+1} & \cdots \\
                & & x_{N_2 N_4}
              \end{pmatrix} \in \R^{N_2, N_4}, \\
          Y = \begin{pmatrix}
                y_1 & \cdots & y_{N_3} \\
                y_{N_3+1} & \cdots \\
                & & y_{N_1 N_3}
              \end{pmatrix} \in \R^{N_1, N_3}.
      \end{eqnarray*}
\end{enumerate}


\begin{proof}
    Von d) Sei $x = \left(\begin{smallmatrix}
                      x^1 \\
                      \vdots \\
                      x^{N_2}
                    \end{smallmatrix}\right)$
    mit $x^n\in \R^{N_4}$ und $y = \left(\begin{smallmatrix}
                                      y^1 \\
                                      \vdots \\
                                      y^{N_1}
                                    \end{smallmatrix}\right)$
    mit $y^k\in \R^{N_3}$.

    Dann gilt
    \begin{eqnarray*}
        x = \sum_{n=1}^{N_2} e^n_{N_2} \otimes x^n, \qquad
        X = \sum_{n=1}^{N_2} e^n_{N_2} \otimes (x^n)^T, \\
        y = \sum_{k=1}^{N_1} e^k_{N_1} \otimes y^k, \qquad
        Y = \sum_{k=1}^{N_1} e^k_{N_1} \otimes (y^k)^T.
    \end{eqnarray*}
    Ferner gilt
    \begin{eqnarray*}
            B X C^T
        &=& \left(\sum_{k=1}^{N_1} \sum_{n=1}^{N_2} B[k, n] \left[e^k_{N_1}
            \otimes \left(e^n_{N_2}\right)^T\right]\right) X C^T \\
        &=& \sum_{k=1}^{N_1} e^k_{N_1} \otimes \Biggl[\sum_{n=1}^{N_2} B[k, n]
            \underbrace{\left(e^n_{N_2}\right)^T X C^T}
            _{= \left(x^n\right)^T C^T = \left(C x^n\right)^T}\Biggr].
    \end{eqnarray*}
    Setze $(y^k)^T = \sum_{n=1}^{N_2} B[k, n] (C x^n)^T$,
    dann folgt mit
    \begin{eqnarray*}
            (B \otimes C) x
        &=& \sum_{n=1}^{N_2} \left(B e^n_{N_2}\right) \otimes (C x^n) \\
        &=& \sum_{k=1}^{N_1} e^k_{N_1} \otimes
            \Biggl[\underbrace{\sum_{n=1}^{N_2} B[k, n] C x^n}_{= y^k}\Biggr].
    \end{eqnarray*}
    die Behauptung.
\end{proof}


\begin{Lemma}
    \label{lem:2.10}
    Seien $B \in \R^{N_1, N_1}, \ C \in \R^{N_2, N_2}$ diagonalisierbar mit
    \begin{eqnarray*}
        Q^{-1} B Q &=& D_1 = diag(\lambda_n),
        \quad \text{wobei }
        Q = (q^1, \cdots, q^{N_1}) \\
        P^{-1} C P &=& D_2 = diag(\mu_k),
        \quad \text{wobei }
        P = (p^1, \cdots, p^{N_2})
    \end{eqnarray*}
    und $q^n, \ p^k$ ONB aus Eigenvektoren.
    Dann ist $B \otimes C$ diagonalisierbar mit Eigenwerten
    $\lambda_n \mu_k$ und Eigenvektoren $q^n \otimes p^k \in \R^{N_1 N_2}$.
\end{Lemma}


\begin{proof}
    Es gilt
    \begin{eqnarray*}
          (B \otimes C) (q^n \otimes p^k)
        = (B q^n) \otimes (C p^k)
        = (\lambda_n q^n) \otimes (\mu_k p^k)
        = (\lambda_n \mu_k) (q^n \otimes p^k).
    \end{eqnarray*}
    Die Eigenvektoren sind somit $q^n \otimes p^k$ mit den dazugehörigen
    Eigenwerten $\lambda_n \mu_k$. Die Eigenschaft b) des Kronecker-Produkts
    liefert uns die Diagonalisierbarkeit, da $q^n \otimes p^k$
    eine ONB aus Eigenvektoren von $B \otimes C$ bildet.
\end{proof}


\begin{Anwendung}
    Betrachte $A = I_{N_1} \otimes T_{N_2} + T_{N_1} \otimes I_{N_2}$.

    Seien dazu $T_{N_1}, \ T_{N_2}$ symmetrisch und positiv definit. Dann
    existieren orthogonale Matrizen $Q = (q^1, \cdots, q^{N_1}), \
    P = (p^1, \cdots, p^{N_2})$ mit
    \begin{eqnarray*}
        Q^T T_{N_1} Q = D_1 = diag(\lambda_n), \quad
        P^T T_{N_2} P = D_2 = diag(\mu_k)
    \end{eqnarray*}
    und es gilt
    \begin{eqnarray*}
            A (q^n \otimes p^k)
        &=& q^n \otimes T_{N_2} p^k + T_{N_1} q^n \otimes p^k \\
        &=& (\lambda_n + \mu_k) (q^n \otimes p^k),
    \end{eqnarray*}
    sodass
    \begin{eqnarray*}
            A
        &=& \sum_{n, k} (\lambda_n + \mu_k) (q^n \otimes p^k)
            (q^n \otimes p^k)^T, \\
            A^{-1}
        &=& \sum_{n, k} \frac{1}{\lambda_n + \mu_k} (q^n \otimes p^k)
            (q^n \otimes p^k)^T,
    \end{eqnarray*}
    denn $q^n \otimes p^k$ ist ONB in $\R^{N_1 N_2}$. D.h. $(Q \otimes P)^T
    (Q \otimes P) = I_{N_1} \otimes I_{N_2}$.

    Mit der Matrixschreibweise folgt
    \begin{eqnarray*}
        A(Q \otimes P) = (Q \otimes P)
                         (I_{N_1} \otimes D_2 + D_1 \otimes I_{N_2})
    \end{eqnarray*}
    und damit
    \begin{eqnarray*}
            A
        &=& (Q \otimes P)
            (I_{N_1} \otimes D_2 + D_1 \otimes I_{N_2})
            (Q^T \otimes P^T), \\
            A^{-1}
        &=& (Q \otimes P)
            (I_{N_1} \otimes D_2 + D_1 \otimes I_{N_2})^{-1}
            (Q^T \otimes P^T).
    \end{eqnarray*}
\end{Anwendung}


\begin{Algorithmus}
    Zum lösen von $Au = f$.
    \begin{itemize}
        \item[S1)]
	    Berechne $y = (Q^T \otimes P^T) f$, d.h.
        $Y = Q^T F P = Q^T (P^T F^T)^T$ mit
	    \begin{eqnarray*}
            F = \begin{pmatrix}
                  f_1 & \cdots & f_{N_2} \\
                  f_{N_2+1} & \cdots \\
                  \vdots
                \end{pmatrix}, \qquad
            Y = \begin{pmatrix}
                    y_1 & \cdots & y_{N_2} \\
                    y_{N_2+1} & \cdots \\
                    \vdots
                \end{pmatrix}.
	    \end{eqnarray*}
	\item[S2)]
	    Berechne $x = (I_{N_1} \otimes D_2 + D_1 \otimes I_{N_2})^{-1} y$, d.h.
	    $X[n, k] = \frac{1}{\lambda_n + \mu_k} Y[n, k]$.
	\item[S3)]
	    Berechne $u = (Q \otimes P) x$, d.h.
        $U = QXP^T = Q (P X^T)^T$ mit
	    \begin{eqnarray*}
            X = \begin{pmatrix}
                    x_1 & \cdots & x_{N_2} \\
                    x_{N_2+1} & \cdots \\
                    \vdots
                \end{pmatrix}, \qquad
            U = \begin{pmatrix}
                    u_1 & \cdots & u_{N_2} \\
                    u_{N_2+1} & \cdots \\
                    \vdots
                \end{pmatrix}.
	    \end{eqnarray*}
    \end{itemize}
\end{Algorithmus}
    

Im Folgenden Lemma setze $N = N_1$ oder $N = N_2$.


\begin{Lemma}
    \label{lem:2.11}
    Die Matrix $T_N = tridiag(-1, 2, -1)$ hat die Eigenwerte $\lambda_n = 2 - 2
    \cos(\theta_n)$ mit $\theta_n = \frac{n \pi}{N+1}$ und Eigenvektoren
    $\tilde q^n = (\sin(j \theta_n))_{j=1,\dots,N}$. 
\end{Lemma}


\begin{proof}
    Sei
    \begin{eqnarray*}
        \omega = \exp(i \theta_1) = \exp\left(i \frac{2 \pi}{2 (N+1)}\right) =
        \cos(\theta_1) + i \sin(\theta_1) \in \C
    \end{eqnarray*}
    die $2 (N+1)$-te Einheitswurzel, d.h. $\omega^{N+1} = -1$.
    Dann gilt mit
    \begin{eqnarray*}
          \hat{q}^n
        = \frac{1}{2 i} \left(\omega^{jn} - \omega^{-jn}\right)_{j=0,\dots,N+1},
        \qquad \hat{q}^n_0 = \hat{q}^n_{N+1} = 0
    \end{eqnarray*}
    und
    \begin{eqnarray*}
            -\hat{q}^n_{j-1} + 2 \hat{q}^n_{j} - \hat{q}^n_{j+1}
        &=& \frac{1}{2i} \omega^{jn} \left(-\omega^{-n} + 2 - \omega^n\right)
            - \frac{1}{2i} \omega^{-jn} \left(-\omega^n + 2 - \omega^{-n}\right)
            \\
        &=& \hat{q}_j^n \left(2 - \left(\omega^n + \omega^{-n}\right)\right) \\
        &=& \hat{q}_j^n (2 - 2\cos(\theta_n)),
    \end{eqnarray*}
    dass $T_N \tilde{q}^n = \lambda_n \tilde{q}^n$.
\end{proof}


\subsection{FFT Fast-Fourier-Transformation}


\begin{Lemma}
    \label{lem:2.12}
    Sei $N \in \N, \ \omega = \omega_N = \exp\left(i \frac{2 \pi}{N}\right)$
    die $N$-te Einheitswurzel und
    \begin{eqnarray*}
        F_N = \left(\omega_N^{nk}\right)_{n, k = 0, \cdots, N - 1}
        = \begin{pmatrix}
              1 & 1 & 1 & \cdots & 1 \\
              1 & \omega & \omega^2 & \cdots & \omega^{N - 1} \\
              1 & \omega^2 & \omega^4 & \cdots & \omega^{2(N - 1)} \\
              \vdots & \vdots &\vdots & & \vdots \\
              1 & \omega^{N - 1} & \omega^{2(N - 1)} & \cdots
              & \omega^{(N - 1)^2}
          \end{pmatrix}\in \C^{N, N}
    \end{eqnarray*}
    die \emph{Fouriermatrix}. Dann gilt $F^{-1} = \frac{1}{N} \overline{F}$, d.h
    $\sqrt{\frac{1}{N}} F$ ist unitär.
\end{Lemma}


\begin{proof}
    Es gilt
    \begin{eqnarray*}
          F_N \overline F_N
        = \left(\sum_{j=0}^{N-1} \omega^{nj} \omega^{-jk}\right)
          _{n, k = 0, \cdots, N - 1}.
    \end{eqnarray*}
    Dann folgt
    \begin{itemize}
	\item[1)]
	    für $n = k \colon \sum_{j=0}^{N-1} \omega^0 = N$.
	\item[2)]
	    für $n \not = k$: Definiere dazu $\eta = \omega^{n-k} \not = 1$.
	    Damit folgt $\eta^N = 1$ und
	    \begin{eqnarray*}
            0 = \frac{1 - \eta^N}{1 - \eta} = \sum_{j=0}^{N-1} \eta^j
              = \sum_{j=0}^{N-1} \omega^{nj} \omega^{-jk}.
	    \end{eqnarray*}
    \end{itemize}
    Insgesamt ergibt sich $F_N \overline F_N = N I_N$.
\end{proof}


\begin{Anwendung}
    Sei $N = 2 (N_1 + 1)$ und $S_N = \Im(F_N) = \frac{1}{2i}
    (F_N - \overline F_N) = \left(\sin\left(nk \frac{2 \pi}{N}\right)\right)
    _{n, k = 0, \dots, N - 1}$. Also
    \begin{eqnarray*}
          S_N
        = \begin{pmatrix}
              0 & \cdots & 0 & \cdots & 0 \\
              \vdots & \tilde Q & \vdots & -\tilde Q & \vdots \\
              0 & \cdots & 0 & \cdots & 0 \\
              \vdots & -\tilde Q & \vdots & \tilde Q & \vdots \\
              0 & \cdots & 0 & \cdots & 0
          \end{pmatrix} \quad
          \text{mit } \tilde Q = S_N [1:N_1, 1:N_1].
    \end{eqnarray*}
    Für $Q = \sqrt{\frac{2}{N_1 + 1}} \tilde Q$ gilt dann $Q Q^T = I_{N_1}$
    und somit
    \begin{eqnarray*}
          Q^T T_{N_1} Q
        = \diag\left(2 - 2\cos\left(\frac{2 n \pi}{N}\right)\right),
    \end{eqnarray*}
    denn $S_N^2 = -\frac{1}{4} (F_N^2 - F_N \overline F_N - \overline F_N F_N
    + \overline F_N^2)$ und $F_N^2[n,k] = 0$ für $n,k = 1, \cdots, N_1$.

    Somit
    $S_N^2 [1:N_1, 1:N_1] = \frac{N}{2} I_{N_1} = 2 Q^2$.
\end{Anwendung}


\begin{Lemma}
    \label{lem:2.13}
    Sei $N = 2 M \in \N$ gerade und $y = F_N x \in \C^N$. Dann gilt
    \begin{eqnarray*}
            y_{2k}
        &=& \sum_{n=0}^{M-1} x_n^+ \omega_{M}^{kn}
            \qquad \text{mit} \qquad x_n^+ = x_n + x_{M+n}, \\
            y_{2k+1}
        &=& \sum_{n=0}^{M-1} x_n^- \omega_{M}^{kn}
            \qquad \text{mit} \qquad x_n^- = (x_n - x_{M+n})
            \omega_N^n.
    \end{eqnarray*}
\end{Lemma}


\begin{proof}
    Es gilt
    \begin{eqnarray*}
        \omega_N^{2kn} = \omega_M^{kn} \text{ und } \omega_N^{(2k+1)n} = 
        \omega_M^{kn} \omega_N^n.
    \end{eqnarray*}
    Damit folgt
    \begin{eqnarray*}
            y_{2k}
        &=& \sum_{n=0}^{N-1} x_n \omega_N^{2kn} \\
        &=& \sum_{n=0}^{M-1} x_n \omega_M^{kn} + \sum_{n=M}^{N-1} x_n
            \omega_M^{kn} \\
        &=& \sum_{n=0}^{M-1} x_n^+ \omega_M^{kn}
    \end{eqnarray*}
    und
    \begin{eqnarray*}
            y_{2k+1}
        &=& \sum_{n=0}^{N-1} x_n \omega_N^{(2k+1)n} \\
        &=& \sum_{n=0}^{M-1} x_n \omega_M^{kn} \omega_N^n
            + \sum_{n=M}^{N-1} x_n \omega_M^{kn} \omega_N^n \\
        &=& \sum_{n=0}^{M-1} \omega_N^n \biggl(x_n \omega_M^{kn} + x_{n+M}
            \omega_M^{kn} \underbrace{\omega_M^{kM}}_{= 1}
            \underbrace{\omega_N^M}_{= -1}\biggr) \\
        &=& \sum_{n=0}^{M-1} x_n^- \omega_M^{kn}.
    \end{eqnarray*}
    Somit folgt die Behauptung.
\end{proof}


\begin{Algorithmus}
    FFT-Algorithmus für die Berechnung von $y = F_N x$ für $N = 2^K$.
    \begin{itemize}
        \item[S1)]
	    Wenn $N = 1$ und $y = x$: STOP
	\item[S2)]
	    Definiere
	    \begin{eqnarray*}
                x^+
            &=& x\left[0 : \frac{N}{2} - 1\right]
                + x\left[\frac{N}{2} : N - 1\right]\in \C^\frac{N}{2} \\
                x^-
            &=& \diag\left(\omega_N^n\right)
                \left(x\left[0 : \frac{N}{2} - 1\right]
                - x\left[\frac{N}{2} : N - 1\right]\right)\in \C^\frac{N}{2}
	    \end{eqnarray*}
%	    mit $\diag(\omega_N^n) \in \C^\frac{N}{2}$
%	    für $n = 0, \cdots, \frac{N}{2} - 1$
	\item[S3)]
	    Berechne $y^+ = F_\frac{N}{2} x^+, \ y^{-} = F_\frac{N}{2} x^-$
	\item[S4)]
	    Berechne $y = (y^+[0], y^-[0], y^+[1], y^-[1], \cdots) \in \C^N$: STOP
    \end{itemize}
\end{Algorithmus}


\begin{Satz}
    \label{satz:2.14}
    Der FFT-Algorithmus benötigt $N \log(N)$ Operationen.
\end{Satz}


\begin{proof} 
    Speichere einen Vektor $\left(\omega_N^n\right)\in \C^N$.

    Dann erfordert S2) im Schritt $k = K, K-1, \dots, 1$ bei der Durchführung
    $2^{K-k}$-Operationen für die Additionen und
    $\frac{1}{2} \cdot 2^{K-k}$-Operationen für die Multiplikationen.
    S2) wird dabei $\frac{N}{2^{K-k}}$ mal aufgerufen, d.h.
    \begin{eqnarray*}
        2^{K-k} \cdot \frac{N}{2^{K-k}} = N \text{ Additionen}
    \end{eqnarray*}
    und
    \begin{eqnarray*}
        \frac{1}{2} \cdot 2^{K-k} \cdot \frac{N}{2^{K-k}} = \frac{N}{2}
        \text{ Multiplikationen}.
    \end{eqnarray*}
    Für $N=2^K$ wird S3) $K$ mal aufgerufen, d.h.
    \begin{eqnarray*}
        K \cdot N \text{ Additionen} + K \cdot \frac{N}{2}
        \text{ Multiplikationen}.
    \end{eqnarray*}
    Da $K$ in $O(\log(N))$ folgt insgesamt ein Aufwand von $O(N \log(N))$
    Operationen.
\end{proof}


\begin{Bemerkung}
    Effiziente Implementierung erfolgt durch \emph{Bitumkehr}. Dabei wird
    $(\omega_N)$ als Vektor abgespeichert.
\end{Bemerkung}


\begin{Anwendung}
    Sei $N = 2^K = 2 (N_1 + 1)$ und $\tilde Q = S[1:N_1, 1:N_1]$ mit
    $S_N = \frac{1}{2i} (F_N - \overline F_N)$.

    Dann erfolgt die Berechnung von $y = \tilde Q x$ durch
    \begin{eqnarray*}
            \hat x
        &=& (0, x_1, \cdots, x_{N_1}, 0, -x_{N_1}, \cdots, -x_1)^T \in \R^N, \\
            \hat y
        &=& F_N \hat x \in \C^N.
    \end{eqnarray*}
    Das bedeutet $y = \frac{1}{2i} (\hat y_1, \cdots, \hat y_{N_1})^T \in
    \R^{N_1}$, denn für $k = 1, \cdots, N_1$ gilt
    \begin{eqnarray*}
          \hat y_k
        = \sum_{n=0}^{N-1} \hat x_n \omega_N^{nk}
        = \sum_{n=1}^{N_1}
          x_n \left(\omega_N^{nk} - \omega_N^{-nk}\right)
        = 2i \sum_{n=1}^{N_1} x_n \sin\left(\frac{2 n k \pi}{N}\right).
    \end{eqnarray*}
\end{Anwendung}


Aufwand zur Berechnung von $y = Ax$:

Für $A = (Q^T \otimes P^T) (D_1 \otimes I_{N_2} + I_{N_1} \otimes
D_2)(Q \otimes P)$ ergibt sich ein Aufwand von 
\begin{eqnarray*}
    2 (N_1 (N_2 \log(N_2)) + N_2 (N_1 \log(N_1))) + N_1 N_2 = O(N_1 N_2
    \log(N_1 N_2))
\end{eqnarray*}
Operationen.


\begin{Bemerkung}
    Für alle \emph{zirkulanten Matrizen}
    \begin{eqnarray*}
        Z = \begin{pmatrix}
                z_0 & z_1 & \cdots & z_{N-1} \\
                & \ddots & \ddots \\
                & & & z_1 \\
                z_1 & & & z_0
            \end{pmatrix} \in \C^{N,N}
    \end{eqnarray*}
    gilt $F_N Z \overline F_N = \diag(\lambda_N)$.
\end{Bemerkung}


Daher lässt sich die Methode auf periodische oder Neumann-Randbedingungen
übertragen.


\subsubsection{Zyklische Reduktion}

Sei $Q^T T_1 Q = D$ diagonal und $T_2$ tridiagonal. Dann ist
\begin{eqnarray*}
      (Q^T \otimes I)
      (T_1 \otimes I + I \otimes T_2) (Q \otimes I)
    = D \otimes I + I \otimes T_2
\end{eqnarray*}
Block-tridiagonal.


$\textbf{Problem \ in \ parallelen \ Rechnern:}$

Berechnen von $Q^T T_1 Q$ erfordert (z.B.) zeilenweise Verteilung.

(Direktes) Lösen von $(d_n I + T_2) x = y$ erfordert spaltenweise Verteilung.

$\textbf{Idee:}$

Für $N = 2^K - 1$ reduziere das LGS $T^{(0)} x^{(0)} = y^{(0)} \in \R^{N}$ zu
einem LGS $T^{(1)} x^{(1)} = y^{(1)} \in \R^\frac{N}{2}$ rekursiv mit
$x_n^{(1)} = x_{2n}^{(0)}$.


\begin{Beispiel}
    Sei $N = 2^3$. Dann betrachte
    \begin{eqnarray*}
        \begin{pmatrix}
            2 & -1 \\
            -1 & 2 & -1 \\
            & -1 & 2 & -1 \\
            & & \ddots & \ddots & \ddots \\
            \\
            \\
            & & & & & & & -1 \\
            & & & & & & -1 & 2
        \end{pmatrix}
        \begin{pmatrix}
            x_1 \\ \vdots \\ \\ \\ \\ \\ \\ x_7
        \end{pmatrix}
        =
        \begin{pmatrix}
            y_1 \\ \vdots \\ \\ \\ \\ \\ \\ y_7
        \end{pmatrix}.
    \end{eqnarray*}
    Multiplikation der 1-ten und 3-ten Zeile mit $\frac{1}{2}$ und
    anschließende Addition mit der 2-ten Zeile ergibt folgendes LGS
    \begin{eqnarray*}
        \begin{pmatrix}
            1 & -\frac{1}{2} & 0 \\
            -\frac{1}{2} & 1 & -\frac{1}{2} \\
            0 & -\frac{1}{2} & 1
        \end{pmatrix}
        \begin{pmatrix}
            x_2 \\ x_4 \\ x_6
        \end{pmatrix}
        =
        \begin{pmatrix}
            y_2 + \frac{1}{2} y_1 + \frac{1}{2} y_3 \\
            y_4 + \frac{1}{2} y_3 + \frac{1}{2} y_5 \\
            y_6 + \frac{1}{2} y_5 + \frac{1}{2} y_7
        \end{pmatrix}
    \end{eqnarray*}
    Durch wiederholen des vorherigen Schrittes erhält man
    \begin{eqnarray*}
          \frac{1}{2} x_4
        = y_4 + \frac{1}{2} (y_3 + y_5) + \frac{1}{2} \left(y_2 + \frac{1}{2}
          (y_1 + y_3) + y_6 + \frac{1}{2} (y_5 + y_7)\right).
    \end{eqnarray*}
    Einsetzten ergibt erst $x_2, \ x_6$ und dann $x_1, \ x_3, \ x_5, \ x_7$.
\end{Beispiel}



\paragraph{Druckkorrektur bei der Approximation der Navier-Stokes-Gleichungen}



\begin{eqnarray*}
    \partial_t u + \sum_{i=0}^d u_i \partial_i u -\nu \Delta u + \nabla p &=& 0
    \\
    \nabla \cdot u &=& 0
\end{eqnarray*}
Geschwindigkeit $u(x,t) \in \R^d$, Druck $p(x,t) \in \R$.

Finite Differnzen in Raum und Zeit ($t_n = n \Delta t$):

Bestimme $u_h^n \in V_h(0)^d, \ p_h^n \in V_h$.

Bei gegebenen $u_h^{n-1}$ berechne zunächst $\tilde u_h^n$ durch
\begin{eqnarray*}
    \frac{1}{\Delta t} (\tilde u_h^n - u_h^{n-1}) + \sum_{i=0}^d u_{h,i}^{n-1}
    \partial_{h,i}^0 u_h^{n-1} - \nu \Delta_h u_h^{n-1} + \nabla_h p^{n-1} = 0.
\end{eqnarray*}
Mit dem zuvor berechneten $\tilde u_h^n$ erhält man $u_h^n$ durch lösen der
Gleichung
\begin{eqnarray*}
    -\Delta_h q_h = \sum_{i=0}^d \partial_{h,i}^- \tilde u_{h,i}^n.
\end{eqnarray*}
Die Lösung ist dann gegeben durch
\begin{eqnarray*}
    u_h^n = \tilde u_h^n - (\partial_{h,i}^+ q)_i.
\end{eqnarray*}
Dabei ist
\begin{eqnarray*}
    \sum_{i=0}^d \partial_{h,i}^- u_h^n = \sum_{i=0}^d \partial_{h,i}^-
    \tilde u_{h,i}^n - \Delta_h q_h = 0
\end{eqnarray*}
das Problem diskret divergenzfrei.



\subsection{Eigenschaften von $-\Delta$ in $\Omega = (0,1)^2$}


$L_2(\Omega)$ ist die Menge aller äquivalenzklassen der quadratintegrierbaren
Funktionen, d.h. $f$ ist Lebesgue-messbar und
\begin{eqnarray*}
    f = g \Leftrightarrow \{x \in \Omega: f(x) \not = g(x)\}
    \ \text{ist eine Nullmenge, d.h. Maß 0}.
\end{eqnarray*}
Die stetigen Funktionen $C(\overline\Omega) \subset L_2(\Omega)$ sind dicht in
$L_2(\Omega)$, d.h. zu
\begin{eqnarray*}
    f \in L_2(\Omega) \text{ existiert } f_n \in C(\overline
    \Omega) \text{ mit } \|f - f_n\|_0 \to 0 \text{ für } n \to \infty.
\end{eqnarray*}
$L_2(\Omega)$ ist ein Hilbertraum mit
%\begin{eqnarray*}
    Skalarprodukt $(f, g)_0 = \int_\Omega f g \dx$ und der dadurch induzierten
    Norm $\|f\|_0 = \sqrt{(f, f)_0}$.
%\end{eqnarray*}
Insbesondere ist $L_2(\Omega)$
vollständig, d.h. jede Cauchy-Folge in $L_2(\Omega)$ konvergiert in $L_2(\Omega)$. Konkret bedeutet dies: für eine Cauchy-Folge $(f_n)_{n\in\N}$ in $L_2(\Omega)$, d.h.
\begin{eqnarray*}
    \forall \epsilon > 0 \ \exists N \in \N: \|f_m - f_n\|_0 < \epsilon \
    \forall n, m \ge N,
\end{eqnarray*}
existiert ein Grenzwert in $L_2(\Omega)$, also
\begin{eqnarray*}
    \exists f \in L_2(\Omega) \text{ mit } \lim_{n \to \infty}
    \|f - f_n\|_0 = 0.
\end{eqnarray*}


\begin{Satz}
    \label{satz:2.15}
    Sei $f \in L_2(\Omega)$ mit $(f, g)_0 = 0$ für alle $g \in C(\Omega)$.
    Dann ist $f = 0$ (fast überall, d.h. $\{x \in \Omega: f(x) \not =
    0\}$ ist Nullmenge).
\end{Satz}


\begin{proof}
    Annahme: $\|f\|_0 > 0$.

    Wähle $f_n \in C(\overline \Omega)$ mit $\|f
    - f_n\|_0 \to 0$. Aber
    \begin{eqnarray*}
        \|f - f_n\|_0^2 = \|f\|_0^2 - 2 \underbrace{(f, f_n)_0}_{= 0} +
        \|f_n\|_0^2 \ge \|f\|_0^2,
    \end{eqnarray*}
    was ein Widerspruch zur Voraussetzung ist.
\end{proof}


Wir beobachten, dass im Einheitsquadrat $\Omega = (0, 1)^2$ für
\begin{eqnarray*}
    u_k(x) = 2 \sin(k_1 \pi x_1) \sin(k_2 \pi x_2), \qquad k \in
    \N^2
\end{eqnarray*}
gilt
\begin{eqnarray*}
      -\Delta u_k(x)
    &=& -2 \sum_{i=1}^2 \partial_i^2
        \sin(k_1 \pi x_1) \sin(k_2 \pi x_2) \\
    &=& 2 \sum_{i=1}^2 k_i^2 \pi^2 \sin(k_1 \pi x_1)
        \sin(k_2 \pi x_2) \\
    &=& \lambda_k u_k(x)
\end{eqnarray*}
mit $\lambda_k = (k_1^2 + k_2^2) \pi^2$ und $u_k(x) = 0$ auf
$\partial\Omega$. Demzufolge sind $u_k$ Eigenfunktionen von $-\Delta$ im
Einheitsquadrat!


\begin{Satz}
    \label{satz:2.16}
    $(u_k)_{k\in\N^2}$ ist ein vollständiges Orthonormalsystem in
    $L_2(\Omega)$.
\end{Satz}


\begin{proof}
    Es gilt
    \begin{eqnarray*}
            (u_k, u_{k^\prime})_0
        &=& 4 \int_0^1 \sin(k_1 \pi x_1)
            \sin(k_1^\prime \pi x_1) \,dx_1 \int_0^1 \sin(k_2 \pi x_2)
            \sin(k_2^\prime \pi x_2) \,dx_2 \\
        &=& 0 \qquad \text{für } k \not = k^\prime,
    \end{eqnarray*}
    denn
    \begin{eqnarray*}
        \int_0^1 \sin(n \pi x) \sin(j \pi x) \,dx = \frac{1}{4} \int_0^2
        \Re(\exp(i (n - j) \pi x)) \,dx = 0 \qquad \text{für } n \not = j
    \end{eqnarray*}
    und
    \begin{eqnarray*}
          (u_k, u_k)_0
        = \prod_{i=1}^2 2 \int_0^1 \sin(k_i \pi x_i)^2 \,dx = 1.
    \end{eqnarray*}
    Demzufolge ist $(u_k)_{k\in\N^2}$ ein Orthonormalsystem.

    Nun definieren wir zu $f \in L_2(\Omega)$
    \begin{eqnarray*}
        f^N = \sum_{|k|\le N} (u_k, f)_0 u_k \qquad \text{mit } |k| = k_1 + k_2.
    \end{eqnarray*}
    Dann gilt
    \begin{eqnarray*}
        (f^N, f)_0 = \sum_{|k|\le N} |(u_k, f)_0|^2 = \|f^N\|^2 
    \end{eqnarray*}
    und
    \begin{eqnarray*}
        (f^N, f)_0 \stackrel{\text{CSU}}\le \|f^N\|_0 \|f\|_0.
    \end{eqnarray*}
    Insgesamt folgt
    \begin{eqnarray*}
        \sqrt{\sum_{|k|\le N} |(u_k, f)_0|^2} = \|f^N\|_0 \le \|f\|_0.
    \end{eqnarray*}
    Damit ist $f^N$ Cauchyfolge und es existiert $f^* \in L_2(\Omega)$ mit
    $f^N \to f^*$ und $(f - f^*, u_k)_0 = 0$ für
    alle $k \in \N^2$.

    Für stetige Funktionen $v \in C(\overline\Omega)$ gilt nun,
    dass sie sich durch eine (modifizierte) Fourier-Transformation darstellen
    lassen durch
    \begin{eqnarray*}
        v = \sum_{k\in\N^2} a_k u_k.
    \end{eqnarray*}
    Damit folgt
    \begin{eqnarray*}
        (f - f^*, v)_0 = 0 \qquad \text{für alle } v\in C(\overline\Omega).
    \end{eqnarray*}
    Mit $\eqref{satz:2.15}$ folgt dann $f = f^*$ fast überall und wir erhalten
    die Vollständigkeit.
\end{proof}


\begin{Definition}
    \label{def:2.17}
    Für $s \ge 0$ definiere
    \begin{eqnarray*}
            H_s
        &=& \{u \in L_2(\Omega):
            \sum_{k\in\N^2} \lambda_k^s |(u, u_k)_0|^2 < \infty\}, \\
            H_{-s}
        &=& H_s^\prime = L(H_s, \R)
        =  \{f: H_s \to \R \text{ linear und stetig}\}.
    \end{eqnarray*}
\end{Definition}


\begin{Bemerkung}
    \begin{enumerate}[1)]
	\item
	    $H_s$ und $H_{-s}$ sind Hilberträume mit Skalarprodukt
	    \begin{eqnarray*}
                (u, v)_s
            &=& \sum_{k\in\N^2} \lambda_k^s (u, u_k)_0 (v, u_k)_0 \\
                (f, g)_{-s}
            &=& \sum_{k\in\N^2} \lambda_k^{-s} f(u_k) g(u_k).
	    \end{eqnarray*}
	    $(u_k)_{k\in\N^2}$ ist ein vollständiges Orthogonalsystem in
	    $H_s$ für $s \ge 0$ und

	    $(u_k^\prime)_{k\in\N^2}$ mit
	    $u_k^\prime (v) = (v, u_k)_0$ ist ein vollständiges Orthogonalsystem
	    in $H_{-s}$ für $s \ge 0$.
	\item
	    Der Laplace-Operator $-\Delta: H_s \to H_{s-2}$ ist eine Isometrie,
	    d.h.
	    \begin{eqnarray*}
            \|u\|_s = \|\Delta u\|_{s-2}.
	    \end{eqnarray*}
	    Denn mittels Greenscher Formel und da $u_k$ Eigenfunktion ist gilt
	    \begin{eqnarray*}
            (\Delta u, u_k)_0 = (u, \Delta u_k)_0 = -\lambda_k (u, u_k)_0.
	    \end{eqnarray*}
	    Und damit
	    \begin{eqnarray*}
              \|\Delta u\|_{s-2}^2
            = \sum_{k\in\N^2} \lambda_k^{s-2} (\Delta u, u_k)_0
              (\Delta u, u_k)_0
            = \sum_{k\in\N^2} \lambda_k^2 |(u, u_k)_0|^2
            = \|u\|_s^2.
	    \end{eqnarray*}
	    Insbesondere ist $\Delta$ also stetig und stetig invertierbar.

	    Für $s = 1$ ist $-\Delta: H_1 \to H_{-1}$ selbstadjungiert, d.h.
	    \begin{eqnarray*}
            (\Delta u, v)_{H_{-1} \times H_1} = (\Delta v, u)_{H_{-1} \times
            H_1}
	    \end{eqnarray*}
	\item
	    Sei $L = -\Delta$, dann definiere $L^s :H_t \to H_{t-s}$ durch
	    $L^s v = \sum_{k\in\N^2} \lambda_k^s (v, u_k)_0 u_k$.
	\item
	    Für $s < t$ gilt $H_t \subset H_s$ und die Einbettung $E_{t,s}:
	    H_t \to H_s$ ist stetig mit
	    \begin{eqnarray*}
            \|u\|_s \le \sqrt{\lambda_{11}^{s-t}} \|u\|_t
            \qquad (\lambda_{11} = 2 \pi^2)
	    \end{eqnarray*}
	    Ein Spezialfall ist die Poincar\'e-Ungleichung
	    \begin{eqnarray*}
            \|u\|_0 \le \frac{1}{\sqrt{\lambda_{11}}} \|u\|_1
            \qquad \text{für alle } u \in H_1.
	    \end{eqnarray*}
	\item
	    Sei $s > 0$ und $L^{-s}: H_t \to H_{t+s}$ Lösungsoperator. Dann
	    definiere
	    \begin{eqnarray*}
              L_N^{-s}
            = \sum_{|k|\le N} \lambda_k^{-s} (u, u_k) u_k.
	    \end{eqnarray*}
	    Damit gilt
	    \begin{eqnarray*}
                  \|L^{-s} u - L_N^{-s} u\|_t
            &\le& \left(\min_{|k|>N} \lambda_k\right)^{-s}
                  \left\|\sum_{|k|\le\N} (u, u_k) u_k\right\|_t \\
            &\le& \frac{4 \pi}{N^2} \|u\|_t
            \to   0 \qquad N \to \infty.
	    \end{eqnarray*}
	    Also ist $B = E_{2,0} (-\Delta)^{-1}: L_2(\Omega) \to L_2(\Omega)$
	    durch Operatoren mit endlich dimensionalem Bild approximierbar.

	    $B$ ist kompakter Operator, d.h. wenn $f_n$  beschränkt in
	    $L_2(\Omega)$, dann besitzt $(-\Delta)^{-1} f_n = u_n$ konvergente
	    Teilfolge in $L_2(\Omega)$.
	\item
	    $H_s \subset C(\overline \Omega)$ für $s > \frac{d}{2}$, da
	    $\sum \lambda_k^{-s}$ Cauchy-Folge.
    \end{enumerate}
\end{Bemerkung}
